# this is a sample configuration file
# the program will pick it up, if it is named config.toml

# if this is a testrun
# during a testrun no sink will be triggered
test = false

# number of threads on which the watchers will be executed
thread_count = 4

# if true, the first run will be used to setup
# only on the second run observers will be informed
initial_run = false

# set how often the scraping process will be triggered
# run every 5 minutes (300 seconds)
interval = 300

#-------------
# watchers
#-------------

# there can be multiple watcher blocks
# a watcher defines an endpoint that will be scraped in the specified time interval
# properties found on any of the watched endpoints will be merged into one big result set
[[watcher]]
# this will be added as metadata to each property that is seen by this watcher
city = "Munich"
# this is the endpoint that you want to scrape
# make sure it contains your search criteria
address = "https://www.immobilienscout24.de/Suche/de/bayern/muenchen-kreis/wohnung-mieten?numberofrooms=2.0-&price=-1500.0&livingspace=40.0-&enteredFrom=one_step_search"
# available crawlers are: immoscout, immowelt, wohnungsboerse, wggesucht, sueddeutsche
crawler = "immoscout"
# available contract_types: buy, rent
contract_type = "rent"
# available property_types: house, flat
property_type = "flat"

#-------------
# enrichers
#-------------

# found properties can be geocoded (address will be translated into lat/long coordinates).
# this will decrease notification speed, because properwatcher will pause for 1 second
# after each request (see usage policy of nominatim)
[geocoding]
enabled = false
# nominatim API will be used for geocoding
# either use the global one, or you can also use a local instance
nominatim_url = "https://nominatim.openstreetmap.org/search"
# nominatim is a public free API used by openstreetmap
# we provide a custom user agent here, so they can rate limit their usage
# and block applications that exhaustively access their endpoints
# feel free to append a custom string i.e. properwatcher-flo
user_agent = "properwatcher"

#-------------
# observers
#-------------

# optionally the found properties can be stored in a firebase database.
# the database will also be used to deduplicate found entries.
# if the database is not enabled, properwatcher will only 
[database]
# the database and all related features can be toggled.
enabled = false
# if enabled, the file from auth_json_path will be read and used for authentication.
auth_json_path = "firebase.json"
# collection name
collection_name = "properties"

# found properties can be sent to a given Telegram channel
# therefore, you first need to create a Telegram bot and start a conversation with it.
# you can follow this tutorial's first two steps to create a bot token and chat id:
# https://www.shellhacks.com/telegram-api-send-message-personal-notification-bot/
[telegram]
enabled = false
# API key of your Telegram bot
api_key = "<telegram-bot-api-key>"
# chat id of the conversation with your private bot
# can also be the id of a private group chat
chat_id = "<chat-id>"

# found properties can be forwarded to you via email
[mail]
enabled = false
smtp_server = "smtp.gmail.com"
# your username - in case of gmail, your mail address
# this is also where the notification mails are being sent to
username = "user"
# if you're going with gmail, you need to create an application specific password
# see here: https://support.google.com/mail/answer/185833?hl=en
password = "pass"

# found properties can be appended to a CSV file
# this option is recommended for easy dataset inspection via:
# tableau or microsoft's power bi
[csv]
enabled = false
# output file
# new entries will be appended, if the file already exists
filename = "properwatcher.csv"